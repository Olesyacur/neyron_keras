{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import reuters\n",
    "from tensorflow import keras \n",
    "\n",
    "from keras import layers\n",
    "from keras import models\n",
    "# from keras import optimizers\n",
    "# from keras import losses\n",
    "# from keras import metrics\n",
    "\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(\n",
    "    num_words=10000\n",
    ")\n",
    "\n",
    "# print(train_data[10])\n",
    "\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]]\n",
    ")\n",
    "# print(train_labels[10])\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        for j in sequence: \n",
    "            results[i, j] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "# def to_one_hot(labels, dimension=46):\n",
    "#     results = np.zeros((len(labels), dimension))\n",
    "#     for i, label in enumerate(labels):\n",
    "#         results[i, label] = 1.\n",
    "#     return results\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "new_model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(46, activation='softmax')\n",
    "])\n",
    "\n",
    "new_model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n",
    "history = new_model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=9,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "results = new_model.evaluate(x_test, y_test)\n",
    "print(results)\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Потери на этапе обучения')\n",
    "plt.plot(epochs, val_loss, 'b', label='Потери на этапе проверки')\n",
    "plt.title('Потери на этапах обучения и проверки')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Потери')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Точность на этапе обучения')\n",
    "plt.plot(epochs, val_acc, 'b', label='Точность на этапе проверки')\n",
    "plt.title('Точность на этапах проверки и обучения')\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Точность')\n",
    "plt.legend()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=9,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)\n",
    "\n",
    "import copy\n",
    "\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "print(float(np.sum(hits_array)) / len(test_labels))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
