{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import test\n",
    "from keras.datasets import boston_housing\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()\n",
    "\n",
    "# print(train_data.shape)\n",
    "# print(test_data.shape)\n",
    "# print(train_targets)\n",
    "\n",
    "mean = train_data.mean(axis=0)\n",
    "train_data -= mean\n",
    "std = train_data.std(axis=0)\n",
    "train_data /= std\n",
    "\n",
    "test_data -= mean\n",
    "test_data /= std\n",
    "\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    return model\n",
    "  \n",
    "k = 4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 500\n",
    "# all_scores = []\n",
    "all_mae_histories = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[\n",
    "        i * num_val_samples: (i + 1) * num_val_samples\n",
    "    ]\n",
    "    val_targets = train_targets[\n",
    "        i * num_val_samples: (i + 1) * num_val_samples\n",
    "    ]\n",
    "\n",
    "    partial_train_data = np.concatenate(\n",
    "        [train_data[:i * num_val_samples],\n",
    "         train_data[(i + 1) * num_val_samples:]],\n",
    "         axis=0\n",
    "    )\n",
    "    partial_train_targets = np.concatenate(\n",
    "        [train_targets[:i * num_val_samples],\n",
    "         train_targets[(i + 1) * num_val_samples:]],\n",
    "         axis=0\n",
    "    )\n",
    "\n",
    "    model = build_model()\n",
    "    history = model.fit(\n",
    "        partial_train_data,\n",
    "        partial_train_targets,\n",
    "        validation_data=(val_data, val_targets),\n",
    "        epochs=num_epochs,\n",
    "        batch_size=1,\n",
    "        verbose=0\n",
    "    )\n",
    "    val_mse, val_mae = model.evaluate(\n",
    "        val_data,\n",
    "        val_targets,\n",
    "        verbose=0\n",
    "    )\n",
    "    # for key, value in history.history.items() :\n",
    "    #     print (key, value)\n",
    "    mae_history = history.history['mae']\n",
    "    all_mae_histories.append(mae_history)\n",
    "\n",
    "average_mae_history = [\n",
    "    np.mean([x[i] for x in all_mae_histories]) for i in range (num_epochs)\n",
    "]\n",
    "\n",
    "def smooth_curve(points, factor=0.9):\n",
    "    smoothed_points=[]\n",
    "    for point in points:\n",
    "        if smoothed_points:\n",
    "            previous = smoothed_points[-1]\n",
    "            smoothed_points.append(previous * factor + point * (1 - factor))\n",
    "        else:\n",
    "            smoothed_points.append(point)\n",
    "    return smoothed_points\n",
    "\n",
    "\n",
    "smoothed_mae_history = smooth_curve(average_mae_history[10:])\n",
    "\n",
    "plt.plot(range(1, len(smoothed_mae_history) + 1), smoothed_mae_history)\n",
    "plt.xlabel('Эпохи')\n",
    "plt.ylabel('Оценка MAE')\n",
    "plt.show()\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit(\n",
    "        train_data,\n",
    "        train_targets,\n",
    "        epochs=80,\n",
    "        batch_size=16,\n",
    "        verbose=0\n",
    "  )\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)\n",
    "\n",
    "print(test_mse_score, test_mae_score)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
